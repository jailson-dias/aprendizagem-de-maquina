{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VERSAO ITERAVEL DO PROJETO\n",
    "\n",
    "# Bibliotecas para an√°lise de dados\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from itertools import chain, combinations\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importando arquivo de treino e dividindo os objetos em duas views: mShapeView e mRGBView\n",
    "\n",
    "train = pd.read_csv('segmentation.test.txt', delimiter=',')\n",
    "columns = train.columns.tolist()\n",
    "mShapeView = train.reindex(columns=columns[1:10])\n",
    "mRGBView = train.reindex(columns=columns[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizar e calcular as matrizes de dissimilaridade\n",
    "\n",
    "mShapeViewNorma = normalize(mShapeView, axis=1, norm='l1')\n",
    "mRGBViewNorma = normalize(mRGBView, axis = 1, norm = 'l1')\n",
    "dist = DistanceMetric.get_metric('euclidean')\n",
    "\n",
    "diss_shapeView = dist.pairwise(mShapeViewNorma)\n",
    "diss_RGBView = dist.pairwise(mRGBViewNorma)\n",
    "#type(diss_shapeView)\n",
    "#np.shape(diss_shapeView)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 2100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrizes = [diss_shapeView, diss_RGBView]\n",
    "np.shape(matrizes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logica do algoritmo\n",
    "#variaveis globais\n",
    "NUM_CLUST = 7\n",
    "NUM_OBJ = 2100\n",
    "NUM_PESOS = 2\n",
    "NUM_REP = 3\n",
    "VAL_MAX = 10000000\n",
    "pesos = np.ones(2)\n",
    "matrizes = [diss_shapeView, diss_RGBView]\n",
    "\n",
    "\n",
    "random.seed(100)\n",
    "\n",
    "\n",
    "E = np.arange(0,2100).tolist() #representa o indice de cada objeto, se acessado pela matriz de dissimilaridade\n",
    "#nesse momento serve para calclar os subconjuntos de card 'q' usados na logica dos representantes\n",
    "\n",
    "#OBS\n",
    "#para a escolha dos prototipos a ideia eh testar o matching global dos elementos de um cado cluster Ck\n",
    "#com um canditado e_h a representante, onde h varia de 0 a n, n sendo o numero de elementos do conjunto E\n",
    "#depois ordena a lista que contem o valor dos matchings e pega os 3 melhores (melhor signifcand)\n",
    "#A distancia para os 3 elementos dos representantes eh utilizada apenas na etape de definir a nova particao\n",
    "\n",
    "#definir os prototipos; inicializar de forma aletoria\n",
    "prototipos = []\n",
    "#definir a particao\n",
    "particao = [] #particao eh composta por uma lista de clusters, cada um contendo os indices dos elementos\n",
    "#passo 1 - inicializacao\n",
    "prototipos_novos = [] #prototipos G_k_t do artigo\n",
    "\n",
    "\n",
    "\n",
    "#------------------funcoes auxiliares do estagio 2-------------------------------------\n",
    "#o termo referente ao match global dos elementos dos clusters com os prototipos,\n",
    "#ponderado pela matriz acessada pelo indice. Esse termo eh util na computacao\n",
    "#do melhor peso e eh retornado pela funcao abaixo\n",
    "def match_global(indice):     #(prototipos, particao, indice):\n",
    "    resultado = np.zeros(1) #tem que ver se esse resultado consegue fazera divisao corretamente\n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in range(0, NUM_CLUST):\n",
    "\n",
    "        for e_i in particao[k]:\n",
    "\n",
    "            for e in prototipos_novos[k]: #aqui depende de prototipos novos como variavel global\n",
    "                resultado[0] += matrizes[indice][e_i][e] #precisa de indice para as matrizes aqui\n",
    "            #nesse momento match_prot contem o match global de e_i com o prototipo, ponderado pelas duas\n",
    "            #matrizes de dissimilaridade    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return resultado\n",
    "\n",
    "\n",
    "#retorna o lambda referente ao indice passado, representado como lambda j no artigo\n",
    "def melhor_peso(indice):\n",
    "    resultado = np.ones(2) #um para o numerador e outro para o denominador\n",
    "    resultado_aux = 0.0\n",
    "    \n",
    "    for i in range(0, NUM_PESOS):\n",
    "        resultado_aux = match_global(i) #aqui considera todas as matrizes em questao\n",
    "        resultado[0] *= resultado_aux;\n",
    "    \n",
    "    resultado[1] = match_global(indice) #denominador\n",
    "    \n",
    "    resultado[0] = resultado[0]**(1/NUM_PESOS) #numerador\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (resultado[0] / resultado[1])\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#inicializacao dos representantes\n",
    "for i in range(0,NUM_CLUST):\n",
    "    prototipos.append([random.randint(i, 10 + i + i*150),random.randint(i, 50  + i + i*150),random.randint(i,150 + i +  i*150)])\n",
    "    particao.append([])\n",
    "\n",
    "    \n",
    "\n",
    "#Nesse momento o vetor E passa a armazenar o indice do cluster k ao qual o elemento indexado pertence\n",
    "for i in range(0, NUM_OBJ):\n",
    "    indice_atual = 0 #indice do cluster que minimiza o criterio J para o elemento e_i\n",
    "    criterio_atual = VAL_MAX #criterio atual para elemento e_im; quer minimizar o criterio\n",
    "    \n",
    "    for index_prot, prot in enumerate(prototipos, start = 0):\n",
    "        #indice_prop = 0\n",
    "        match_prot = 0 #calcula a dissimilaridade de e_i com cada elemento do prototipo\n",
    "        for j, val_peso in enumerate(pesos, start = 0): #num de pesos eh igual do de matrizes\n",
    "            \n",
    "            for e in prot:\n",
    "                match_prot += val_peso*(matrizes[j][e][i]) #precisa de indice para as matrizes aqui\n",
    "        #nesse momento match_prot contem o match global de e_i com o prototipo, ponderado pelas duas\n",
    "        #matrizes de dissimilaridade\n",
    "        if(match_prot < criterio_atual):\n",
    "            criterio_atual = match_prot\n",
    "            indice_atual = index_prot\n",
    "    #espera chegar aqui com o index do melhor prototipo para e_i. Logo, pode adiciona-lo ao cluster\n",
    "    particao[indice_atual].append(i) #i representa o index do elemento\n",
    "    E[i] = indice_atual\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------parte iteravel do algoritmo------------------------------\n",
    "for cont_iteracao in range(0, 15): #usar uma constante aqui depois\n",
    "    #ESTAGIO 1\n",
    "    #computar os melhores prototipos; \n",
    "    #Aqui usa a nova lista de prototipos\n",
    "    \n",
    "    prototipos_novos = []\n",
    "    \n",
    "    for i in range(0, NUM_CLUST):\n",
    "        prototipos_novos.append([])\n",
    "\n",
    "\n",
    "    for k in range(0,NUM_CLUST):\n",
    "        Rep = []\n",
    "\n",
    "        for h in range(0,NUM_OBJ):\n",
    "            match_candidato = 0 #usa para armazenar o match dos elementos do cluster k\n",
    "            #com o candidato e_h\n",
    "            for j, val_peso in enumerate(pesos, start = 0): #iterador para pesos e matrizes\n",
    "\n",
    "                for obj in particao[k]: #para cada elemento do cluster k\n",
    "                    match_candidato += val_peso*(matrizes[j][obj][h]) #match de um obj do cluster k\n",
    "                    #com o candidato a representante h, ponderado pelo peso j na matriz j\n",
    "            #computou o match do canditato com todos os elementos do cluster\n",
    "            Rep.append([match_candidato, h]) #insere match na primeira posicao pois ordena por ele\n",
    "\n",
    "        #canditados h com matchs calculados, ordena pelo match e pega os 3 melhores \n",
    "        Rep.sort()\n",
    "\n",
    "        for ind in range(0,3): #usar NUM_REP aqui\n",
    "            prototipos_novos[k].append(Rep[ind][1]) #tem que pegar a posicao 1 do Rep que contem o indice\n",
    "    \n",
    "    #ESTAGIO 2\n",
    "    #considera os novos prototipos calculados anteriormente e a particao anterior ou incial\n",
    "    #assume globais todas as variaveis nao declaradas na funcao ou como parametros\n",
    "    #usa as funcoes auxiliares para organizar melhor a logica\n",
    "    #essa eh a parte do codigo REALMENTE responsavel por calcular os pesos das matrizes\n",
    "    for indiz in range(0, NUM_PESOS):\n",
    "        pesos[indiz] = melhor_peso(indiz)\n",
    "\n",
    "    #TERCEIRA PARTE\n",
    "    #alterar o cluster a que pertence um objeto caso se adeque melhor a nova configuracao de \n",
    "    #pesos e prototipos calculados\n",
    "\n",
    "    #ver necessidade de criar um clone da particao ou se simplesmente vai excluindo e adicionando\n",
    "    #elementos nos clusters da particao atual\n",
    "    #o que importa eh achar o melhor match com relacao aos novos prototipos  e pesos\n",
    "    #calculados no passo 1\n",
    "\n",
    "    for i in range(0, NUM_OBJ): #para cada elemento de E\n",
    "        indice_novo = E[i] #indice do cluster atual do elemento i eh E[i], mas inicia o novo igual\n",
    "        criterio_atual = VAL_MAX #criterio atual para elemento e_im; cuidado, quer minimizar o criterio\n",
    "        for index_prot, prot in enumerate(prototipos_novos, start = 0):\n",
    "            #indice_prop = 0\n",
    "            match_prot = 0 #calcula a dissimilaridade de e_i com cada elemento do prototipo\n",
    "            for j, val_peso in enumerate(pesos, start = 0): #num de pesos eh igual do de matrizes\n",
    "\n",
    "                for e in prot:\n",
    "                    match_prot += val_peso*(matrizes[j][e][i]) #precisa de indice para as matrizes aqui\n",
    "            #nesse momento match_prot contem o match global de e_i com o prototipo, ponderado pelas duas\n",
    "            #matrizes de dissimilaridade\n",
    "            if(match_prot < criterio_atual):\n",
    "                criterio_atual = match_prot\n",
    "                indice_novo = index_prot\n",
    "        #espera chegar aqui com o index do melhor prototipo para e_i.\n",
    "        #Agora realiza alteracoes na particao\n",
    "        if(indice_novo != E[i]):\n",
    "            particao[E[i]].remove(i) #remove da particao antiga\n",
    "            particao[indice_novo].append(i) #add no novo cluster\n",
    "            E[i] = indice_novo #atualiza indice do elemento e_i\n",
    "\n",
    "        #particao[indice_atual].append(i) #i representa o index do elemento\n",
    "        \n",
    "    print(cont_iteracao)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "306\n",
      "415\n",
      "168\n",
      "645\n",
      "389\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "for i in particao:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "225\n",
      "495\n",
      "179\n",
      "671\n",
      "356\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "for i in particao:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#teste do assignment inicial dos objetos ao prototipo que otimiza melhor o criterio\n",
    "total = 0\n",
    "for i in range(0, NUM_CLUST):\n",
    "    total += len(particao[i])\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 1, 1, 1, 1, 1, 1, 4, 5, 4, 4, 4, 5, 5, 5, 1, 4, 1, 5]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E[2070:2090]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
